{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'seaborn'",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[8], line 6\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mscipy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msparse\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlinalg\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m svds\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mwarnings\u001b[39;00m\n\u001b[1;32m----> 6\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mseaborn\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01msns\u001b[39;00m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mplt\u001b[39;00m\n\u001b[0;32m      9\u001b[0m warnings\u001b[38;5;241m.\u001b[39mfilterwarnings(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
            "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'seaborn'"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from scipy.sparse import csr_matrix\n",
        "from scipy.sparse.linalg import svds\n",
        "import warnings\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "\n",
        "\n",
        "class BookRecommender:\n",
        "    def __init__(self, n_latent_factors=20):\n",
        "        self.n_latent_factors = n_latent_factors\n",
        "        self.books_df = None\n",
        "        self.ratings_df = None\n",
        "        self.user_book_matrix = None\n",
        "        self.user_mapper = None\n",
        "        self.book_mapper = None\n",
        "        self.reverse_user_mapper = None\n",
        "        self.reverse_book_mapper = None\n",
        "        self.global_mean = None\n",
        "        self.min_rating = 1\n",
        "        self.max_rating = 10\n",
        "\n",
        "\n",
        "    def load_data(self, books_path, ratings_path):\n",
        "        print(\"Loading datasets...\")\n",
        "\n",
        "        self.books_df = pd.read_csv(\n",
        "            books_path,\n",
        "            encoding='latin-1',\n",
        "            usecols=['ISBN', 'Book-Title', 'Book-Author'],\n",
        "            dtype={'ISBN': 'string', 'Book-Title': 'string', 'Book-Author': 'string'}\n",
        "        )\n",
        "\n",
        "        self.books_df['Book-Title'] = self.books_df['Book-Title'].str.strip()\n",
        "        self.books_df['Clean-Title'] = self.books_df['Book-Title'].str.lower()\n",
        "        self.books_df = self.books_df.drop_duplicates(\n",
        "            subset=['Clean-Title', 'Book-Author'],\n",
        "            keep='first'\n",
        "        )\n",
        "\n",
        "        self.ratings_df = pd.read_csv(\n",
        "            ratings_path,\n",
        "            dtype={'User-ID': np.int32, 'ISBN': 'string', 'Book-Rating': np.float32}\n",
        "        )\n",
        "\n",
        "        # Replace 0 ratings with 1 to maintain the 1-10 scale\n",
        "        self.ratings_df.loc[self.ratings_df['Book-Rating'] == 0, 'Book-Rating'] = 1\n",
        "\n",
        "        self.ratings_df = self.ratings_df.merge(\n",
        "            self.books_df[['ISBN']],\n",
        "            on='ISBN',\n",
        "            how='inner'\n",
        "        )\n",
        "\n",
        "        print(f\"Initial shapes:\")\n",
        "        print(f\"Books (after deduplication): {self.books_df.shape}\")\n",
        "        print(f\"Ratings: {self.ratings_df.shape}\")\n",
        "        print(f\"Rating range: {self.min_rating} to {self.max_rating}\")\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    def prepare_matrix(self, min_book_ratings=50, min_user_ratings=10):\n",
        "        print(\"\\nPreparing rating matrix...\")\n",
        "\n",
        "        book_counts = self.ratings_df['ISBN'].value_counts()\n",
        "        user_counts = self.ratings_df['User-ID'].value_counts()\n",
        "\n",
        "        valid_books = book_counts[book_counts >= min_book_ratings].index\n",
        "        valid_users = user_counts[user_counts >= min_user_ratings].index\n",
        "\n",
        "        filtered_ratings = self.ratings_df[\n",
        "            self.ratings_df['ISBN'].isin(valid_books) &\n",
        "            self.ratings_df['User-ID'].isin(valid_users)\n",
        "        ]\n",
        "\n",
        "        self.user_mapper = {uid: idx for idx, uid in enumerate(filtered_ratings['User-ID'].unique())}\n",
        "        self.book_mapper = {isbn: idx for idx, isbn in enumerate(filtered_ratings['ISBN'].unique())}\n",
        "\n",
        "        self.reverse_user_mapper = {idx: uid for uid, idx in self.user_mapper.items()}\n",
        "        self.reverse_book_mapper = {idx: isbn for isbn, idx in self.book_mapper.items()}\n",
        "\n",
        "        rows = filtered_ratings['User-ID'].map(self.user_mapper)\n",
        "        cols = filtered_ratings['ISBN'].map(self.book_mapper)\n",
        "        ratings = filtered_ratings['Book-Rating'].values\n",
        "\n",
        "        self.user_book_matrix = csr_matrix(\n",
        "            (ratings, (rows, cols)),\n",
        "            shape=(len(self.user_mapper), len(self.book_mapper))\n",
        "        )\n",
        "\n",
        "        self.global_mean = float(np.mean(ratings))\n",
        "\n",
        "        print(f\"Matrix shape: {self.user_book_matrix.shape}\")\n",
        "        print(f\"Density: {self.user_book_matrix.nnz / (self.user_book_matrix.shape[0] * self.user_book_matrix.shape[1]):.2%}\")\n",
        "        print(f\"Global mean rating: {self.global_mean:.2f}\")\n",
        "\n",
        "    def train_model(self):\n",
        "        print(\"\\nTraining model...\")\n",
        "\n",
        "        # Calculate user biases\n",
        "        user_ratings_sum = np.asarray(self.user_book_matrix.sum(axis=1)).flatten()\n",
        "        user_ratings_count = np.diff(self.user_book_matrix.indptr)\n",
        "        user_means = np.zeros_like(user_ratings_sum, dtype=float)\n",
        "        mask = user_ratings_count > 0\n",
        "        user_means[mask] = user_ratings_sum[mask] / user_ratings_count[mask]\n",
        "        self.user_bias = user_means - self.global_mean\n",
        "\n",
        "        # Calculate item biases\n",
        "        item_ratings_sum = np.asarray(self.user_book_matrix.sum(axis=0)).flatten()\n",
        "        item_ratings_count = np.diff(self.user_book_matrix.tocsc().indptr)\n",
        "        item_means = np.zeros_like(item_ratings_sum, dtype=float)\n",
        "        mask = item_ratings_count > 0\n",
        "        item_means[mask] = item_ratings_sum[mask] / item_ratings_count[mask]\n",
        "        self.item_bias = item_means - self.global_mean\n",
        "\n",
        "        # Center the matrix\n",
        "        centered_matrix = self.user_book_matrix.copy()\n",
        "        for i, j in zip(*centered_matrix.nonzero()):\n",
        "            centered_matrix[i, j] = (\n",
        "                centered_matrix[i, j] -\n",
        "                self.global_mean -\n",
        "                self.user_bias[i] -\n",
        "                self.item_bias[j]\n",
        "            )\n",
        "\n",
        "        # Perform SVD on the centered matrix\n",
        "        U, sigma, Vt = svds(centered_matrix, k=self.n_latent_factors)\n",
        "\n",
        "        # Store the factorized matrices\n",
        "        self.U = U\n",
        "        self.sigma = np.diag(sigma)\n",
        "        self.Vt = Vt\n",
        "\n",
        "        print(\"Model training completed successfully\")\n",
        "\n",
        "    def predict_rating(self, user_idx, item_idx):\n",
        "        try:\n",
        "            baseline = (\n",
        "                self.global_mean +\n",
        "                self.user_bias[user_idx] +\n",
        "                self.item_bias[item_idx]\n",
        "            )\n",
        "\n",
        "            svd_estimate = np.dot(\n",
        "                np.dot(self.U[user_idx, :], self.sigma),\n",
        "                self.Vt[:, item_idx]\n",
        "            )\n",
        "\n",
        "            predicted = float(baseline + svd_estimate)\n",
        "            return np.clip(predicted, self.min_rating, self.max_rating)\n",
        "        except Exception as e:\n",
        "            print(f\"Error in prediction: {e}\")\n",
        "            return self.global_mean  # Return global mean as fallback\n",
        "\n",
        "\n",
        "    def plot_predicted_ratings(self, user_idx):\n",
        "      predictions = []\n",
        "      rated_items = set(self.user_book_matrix[user_idx].nonzero()[1])\n",
        "      for item_idx in range(self.user_book_matrix.shape[1]):\n",
        "          if item_idx not in rated_items:\n",
        "              pred = self.predict_rating(user_idx, item_idx)\n",
        "              predictions.append(pred)\n",
        "\n",
        "      plt.figure(figsize=(8, 6))\n",
        "      sns.histplot(predictions, bins=10, kde=True, color='green')\n",
        "      plt.title(\"Distribuția Ratingurilor Prezise pentru Utilizator\")\n",
        "      plt.xlabel(\"Rating Prezis\")\n",
        "      plt.ylabel(\"Frecvență\")\n",
        "      plt.show()\n",
        "\n",
        "    def get_recommendations(self, user_id, n_recommendations=10):\n",
        "        if user_id not in self.user_mapper:\n",
        "            print(f\"User {user_id} not found in the dataset\")\n",
        "            return pd.DataFrame()\n",
        "\n",
        "        user_idx = self.user_mapper[user_id]\n",
        "        rated_items = set(self.user_book_matrix[user_idx].nonzero()[1])\n",
        "\n",
        "        predictions = []\n",
        "        for item_idx in range(self.user_book_matrix.shape[1]):\n",
        "            if item_idx not in rated_items:\n",
        "                pred = self.predict_rating(user_idx, item_idx)\n",
        "                if not np.isnan(pred):  # Only include valid predictions\n",
        "                    predictions.append((item_idx, pred))\n",
        "\n",
        "        predictions.sort(key=lambda x: x[1], reverse=True)\n",
        "\n",
        "        recommendations = []\n",
        "        seen_titles = set()\n",
        "\n",
        "        for item_idx, pred_rating in predictions:\n",
        "            if len(recommendations) >= n_recommendations:\n",
        "                break\n",
        "\n",
        "            isbn = self.reverse_book_mapper[item_idx]\n",
        "            book_info = self.books_df[self.books_df['ISBN'] == isbn].iloc[0]\n",
        "\n",
        "            if book_info['Clean-Title'] in seen_titles:\n",
        "                continue\n",
        "\n",
        "            seen_titles.add(book_info['Clean-Title'])\n",
        "            recommendations.append({\n",
        "                'Title': book_info['Book-Title'],\n",
        "                'Author': book_info['Book-Author'],\n",
        "                'ISBN': isbn,\n",
        "                'Predicted Rating': round(pred_rating, 2)\n",
        "            })\n",
        "\n",
        "        self.plot_predicted_ratings(user_idx)\n",
        "\n",
        "        return pd.DataFrame(recommendations)\n",
        "\n",
        "def main():\n",
        "    try:\n",
        "        recommender = BookRecommender(n_latent_factors=50)\n",
        "        recommender.load_data('Books.csv', 'Ratings.csv')\n",
        "        recommender.prepare_matrix(min_book_ratings=10, min_user_ratings=5)\n",
        "        recommender.train_model()\n",
        "\n",
        "        valid_user = list(recommender.user_mapper.keys())[0]\n",
        "        recommendations = recommender.get_recommendations(valid_user)\n",
        "\n",
        "        print(f\"\\nTop recommendations for user {valid_user}:\")\n",
        "        print(\"=\" * 80)\n",
        "        for idx, row in recommendations.iterrows():\n",
        "            print(f\"\\n{idx + 1}. {row['Title']}\")\n",
        "            print(f\"   Author: {row['Author']}\")\n",
        "            print(f\"   ISBN: {row['ISBN']}\")\n",
        "            print(f\"   Predicted Rating: {row['Predicted Rating']}\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"An error occurred: {str(e)}\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
